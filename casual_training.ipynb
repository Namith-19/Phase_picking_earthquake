{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "107d4991",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/namithk/miniconda3/envs/eew/lib/python3.9/site-packages/seisbench/__init__.py:7: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import seisbench.data as sbd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c6bca0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99f7158a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-28 10:57:36,720 | seisbench | WARNING | Output component order not specified, defaulting to 'ZNE'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 1265657\n"
     ]
    }
   ],
   "source": [
    "dataset = sbd.STEAD()\n",
    "print(\"Total samples:\", len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c77c860f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    \"noise\": 0,\n",
    "    \"earthquake_local\": 1\n",
    "}\n",
    "\n",
    "dataset.metadata[\"label\"] = dataset.metadata[\"trace_category\"].map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "833c15ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = dataset.metadata[dataset.metadata[\"split\"] == \"train\"].index\n",
    "dev_indices = dataset.metadata[dataset.metadata[\"split\"] == \"dev\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96056659",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SteadTorchDataset(Dataset):\n",
    "    def __init__(self, dataset, indices):\n",
    "        self.dataset = dataset\n",
    "        self.indices = indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        real_idx = self.indices[idx]\n",
    "\n",
    "        waveform = self.dataset.get_waveforms([real_idx])[0]\n",
    "        label = dataset.metadata.iloc[real_idx][\"label\"]\n",
    "\n",
    "        waveform = torch.tensor(waveform, dtype=torch.float32)\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "        return waveform, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "019b17ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SteadTorchDataset(dataset, train_indices)\n",
    "dev_dataset = SteadTorchDataset(dataset, dev_indices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=64, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59a4d85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalConv1d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation=1):\n",
    "        super(CausalConv1d, self).__init__()\n",
    "        self.padding = (kernel_size - 1) * dilation\n",
    "        self.conv = nn.Conv1d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size,\n",
    "            padding=0,\n",
    "            dilation=dilation\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.pad(x, (self.padding, 0))\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "272bfaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation):\n",
    "        super(CausalBlock, self).__init__()\n",
    "\n",
    "        self.conv = CausalConv1d(in_channels, out_channels, kernel_size, dilation)\n",
    "        self.bn = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29073949",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalTCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CausalTCN, self).__init__()\n",
    "\n",
    "        self.block1 = CausalBlock(3, 16, kernel_size=5, dilation=1)\n",
    "        self.block2 = CausalBlock(16, 32, kernel_size=5, dilation=2)\n",
    "        self.block3 = CausalBlock(32, 64, kernel_size=5, dilation=4)\n",
    "        self.block4 = CausalBlock(64, 64, kernel_size=5, dilation=8)\n",
    "\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.squeeze(-1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a80263e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CausalTCN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c5bb167",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dataset.metadata.loc[train_indices][\"label\"].values\n",
    "classes = np.unique(labels)\n",
    "\n",
    "weights = compute_class_weight(\"balanced\", classes=classes, y=labels)\n",
    "\n",
    "pos_weight = torch.tensor([weights[0] / weights[1]]).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6b49ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "021cc863",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for x, y in loader:\n",
    "        x = x.to(device)\n",
    "        y = y.unsqueeze(1).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56045daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.unsqueeze(1).to(device)\n",
    "\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = torch.sigmoid(outputs) > 0.5\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return total_loss / len(loader), accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9174308",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_one_epoch(model, train_loader)\n",
    "    val_loss, val_acc = evaluate(model, dev_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}\")\n",
    "    print(f\"Val Accuracy: {val_acc:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"best_causal_tcn.pth\")\n",
    "        print(\"âœ… Best model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67a1bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eew",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
