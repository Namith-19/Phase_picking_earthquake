{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7958a345",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import seisbench.data as sbd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77168929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Device Checking\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84f113f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-03-01 11:58:20,884 | seisbench | WARNING | Output component order not specified, defaulting to 'ZNE'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 215161\n",
      "Validation samples: 63283\n"
     ]
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "dataset = sbd.STEAD()\n",
    "\n",
    "# Label Encoding simple\n",
    "label_map = {\"noise\": 0, \"earthquake_local\": 1}\n",
    "dataset.metadata[\"label\"] = dataset.metadata[\"trace_category\"].map(label_map)\n",
    "\n",
    "# Spliting the dataset\n",
    "train_indices = dataset.metadata[dataset.metadata[\"split\"] == \"train\"].index\n",
    "dev_indices = dataset.metadata[dataset.metadata[\"split\"] == \"dev\"].index\n",
    "\n",
    "# 20% sanity mode (Using 20% of the dataset only)\n",
    "train_indices = train_indices[:int(0.2 * len(train_indices))]\n",
    "\n",
    "print(\"Training samples:\", len(train_indices))\n",
    "print(\"Validation samples:\", len(dev_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4e39d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SteadTorchDataset(Dataset):\n",
    "    def __init__(self, dataset, indices, crop_len=3000):\n",
    "        self.dataset = dataset\n",
    "        self.indices = indices\n",
    "        self.crop_len = crop_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        real_idx = self.indices[idx]\n",
    "        wf = self.dataset.get_waveforms([real_idx])[0]\n",
    "\n",
    "        # Crop for speed\n",
    "        wf = wf[:, :self.crop_len]\n",
    "\n",
    "        # Normalize\n",
    "        wf = wf - wf.mean(axis=1, keepdims=True)\n",
    "        wf = wf / (wf.std(axis=1, keepdims=True) + 1e-6)\n",
    "\n",
    "        label = self.dataset.metadata.iloc[real_idx][\"label\"]\n",
    "\n",
    "        return torch.tensor(wf, dtype=torch.float32), \\\n",
    "               torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "\n",
    "train_dataset = SteadTorchDataset(dataset, train_indices)\n",
    "dev_dataset = SteadTorchDataset(dataset, dev_indices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=16,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2,\n",
    "                          pin_memory=True)\n",
    "\n",
    "dev_loader = DataLoader(dev_dataset,\n",
    "                        batch_size=16,\n",
    "                        shuffle=False,\n",
    "                        num_workers=2,\n",
    "                        pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "317d7a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalConv1d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation):\n",
    "        super().__init__()\n",
    "        self.padding = (kernel_size - 1) * dilation\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size,\n",
    "                              padding=0, dilation=dilation)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.pad(x, (self.padding, 0))\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f878770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels, kernel_size, dilation):\n",
    "        super().__init__()\n",
    "        self.conv1 = CausalConv1d(channels, channels, kernel_size, dilation)\n",
    "        self.norm1 = nn.GroupNorm(1, channels)\n",
    "        self.conv2 = CausalConv1d(channels, channels, kernel_size, dilation)\n",
    "        self.norm2 = nn.GroupNorm(1, channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.relu(self.norm1(self.conv1(x)))\n",
    "        out = self.dropout(self.norm2(self.conv2(out)))\n",
    "        out += residual\n",
    "        return self.relu(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "40c6ea40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualCausalTCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input_conv = nn.Conv1d(3, 32, kernel_size=1)\n",
    "\n",
    "        dilations = [1,2,4,8,16,32,64,128]  # 8 blocks\n",
    "\n",
    "        self.blocks = nn.Sequential(\n",
    "            *[ResidualBlock(32, 5, d) for d in dilations]\n",
    "        )\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_conv(x)\n",
    "        x = self.blocks(x)\n",
    "        x = self.pool(x).squeeze(-1)\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "model = ResidualCausalTCN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4339d267",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dataset.metadata.loc[train_indices][\"label\"].values\n",
    "weights = compute_class_weight(\"balanced\",\n",
    "                               classes=np.unique(labels),\n",
    "                               y=labels)\n",
    "\n",
    "pos_weight = torch.tensor([weights[0] / weights[1]]).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa1bd1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(),\n",
    "                              lr=1e-4,\n",
    "                              weight_decay=1e-4)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20)\n",
    "# scaler = torch.amp.GradScaler(device_type='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "93d63cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8038/1242697417.py:1: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    }
   ],
   "source": [
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "def train_one_epoch():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for x, y in train_loader:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.unsqueeze(1).to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in dev_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.unsqueeze(1).to(device)\n",
    "\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).cpu().numpy()\n",
    "            all_preds.extend(preds.flatten())\n",
    "            all_labels.extend(y.cpu().numpy().flatten())\n",
    "\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "\n",
    "    return total_loss / len(dev_loader), precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d16ac65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8038/1242697417.py:13: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    train_loss = train_one_epoch()\n",
    "    val_loss, precision, recall = evaluate()\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"Epoch Time: {time.time() - start:.2f} sec\")\n",
    "    print(\"-\"*40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a4dea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "dummy = torch.randn(1,3,3000).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    start = time.time()\n",
    "    for _ in range(100):\n",
    "        _ = model(dummy)\n",
    "    end = time.time()\n",
    "\n",
    "print(\"Avg inference time per window:\",\n",
    "      (end-start)/100, \"seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eew",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
