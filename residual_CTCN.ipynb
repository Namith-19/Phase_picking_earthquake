{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88903e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/namithk/miniconda3/envs/eew/lib/python3.9/site-packages/seisbench/__init__.py:7: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import seisbench.data as sbd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "224563ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c318e0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-03-01 10:51:11,014 | seisbench | WARNING | Output component order not specified, defaulting to 'ZNE'.\n"
     ]
    }
   ],
   "source": [
    "dataset = sbd.STEAD()\n",
    "\n",
    "label_map = {\"noise\": 0, \"earthquake_local\": 1}\n",
    "dataset.metadata[\"label\"] = dataset.metadata[\"trace_category\"].map(label_map)\n",
    "\n",
    "train_indices = dataset.metadata[dataset.metadata[\"split\"] == \"train\"].index\n",
    "dev_indices = dataset.metadata[dataset.metadata[\"split\"] == \"dev\"].index\n",
    "\n",
    "# ðŸ”¥ SANITY MODE (20% training data)\n",
    "train_indices = train_indices[:int(0.2 * len(train_indices))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f45dd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SteadTorchDataset(Dataset):\n",
    "    def __init__(self, dataset, indices):\n",
    "        self.dataset = dataset\n",
    "        self.indices = indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        real_idx = self.indices[idx]\n",
    "        waveform = self.dataset.get_waveforms([real_idx])[0]\n",
    "\n",
    "        # Per-trace normalization\n",
    "        waveform = waveform - waveform.mean(axis=1, keepdims=True)\n",
    "        waveform = waveform / (waveform.std(axis=1, keepdims=True) + 1e-6)\n",
    "\n",
    "        label = dataset.metadata.iloc[real_idx][\"label\"]\n",
    "\n",
    "        return torch.tensor(waveform, dtype=torch.float32), \\\n",
    "               torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "train_dataset = SteadTorchDataset(dataset, train_indices)\n",
    "dev_dataset = SteadTorchDataset(dataset, dev_indices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83f2854c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalConv1d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation):\n",
    "        super().__init__()\n",
    "        self.padding = (kernel_size - 1) * dilation\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size,\n",
    "                              padding=0, dilation=dilation)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.pad(x, (self.padding, 0))\n",
    "        return self.conv(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4476c57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels, kernel_size, dilation):\n",
    "        super().__init__()\n",
    "        self.conv1 = CausalConv1d(channels, channels, kernel_size, dilation)\n",
    "        self.bn1 = nn.BatchNorm1d(channels)\n",
    "        self.conv2 = CausalConv1d(channels, channels, kernel_size, dilation)\n",
    "        self.bn2 = nn.BatchNorm1d(channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.dropout(self.bn2(self.conv2(out)))\n",
    "        out += residual\n",
    "        return self.relu(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab66aacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualCausalTCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input_conv = nn.Conv1d(3, 64, kernel_size=1)\n",
    "\n",
    "        self.blocks = nn.Sequential(\n",
    "            ResidualBlock(64, 5, 1),\n",
    "            ResidualBlock(64, 5, 2),\n",
    "            ResidualBlock(64, 5, 4),\n",
    "            ResidualBlock(64, 5, 8),\n",
    "            ResidualBlock(64, 5, 16),\n",
    "            ResidualBlock(64, 5, 32),\n",
    "            ResidualBlock(64, 5, 64),\n",
    "            ResidualBlock(64, 5, 128),\n",
    "            ResidualBlock(64, 5, 256)\n",
    "        )\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_conv(x)\n",
    "        x = self.blocks(x)\n",
    "        x = self.pool(x).squeeze(-1)\n",
    "        return self.fc(x)\n",
    "\n",
    "model = ResidualCausalTCN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee80641d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dataset.metadata.loc[train_indices][\"label\"].values\n",
    "weights = compute_class_weight(\"balanced\", classes=np.unique(labels), y=labels)\n",
    "pos_weight = torch.tensor([weights[0] / weights[1]]).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22d5b61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.unsqueeze(1).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in dev_loader:\n",
    "            x, y = x.to(device), y.unsqueeze(1).to(device)\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            total_loss += loss.item()\n",
    "            preds = torch.sigmoid(outputs) > 0.5\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    return total_loss / len(dev_loader), correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34b0b55c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m train_losses, val_losses, val_accuracies \u001b[38;5;241m=\u001b[39m [], [], []\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m----> 5\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     val_loss, val_acc \u001b[38;5;241m=\u001b[39m evaluate()\n\u001b[1;32m      8\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[0;32mIn[9], line 12\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m     11\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 12\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "train_losses, val_losses, val_accuracies = [], [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_one_epoch()\n",
    "    val_loss, val_acc = evaluate()\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}\")\n",
    "    print(f\"Val Accuracy: {val_acc:.4f}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a24132",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(train_losses, marker='o', label=\"Training Loss\")\n",
    "plt.plot(val_losses, marker='s', label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"causal_tcn_loss.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(val_accuracies, marker='o')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.title(\"Validation Accuracy\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"causal_tcn_accuracy.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5ab3f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eew",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
